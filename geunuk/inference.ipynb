{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import timm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    # 원본 (512, 384)\n",
    "    'IMG_SIZE_H': 512,\n",
    "    'IMG_SIZE_W': 384,\n",
    "    'EPOCHS': 100,\n",
    "    'LEARNING_RATE': 2e-5,\n",
    "    'BATCH_SIZE': 32,\n",
    "    'SEED': 909,\n",
    "    'PAATIENCE_LIMIT': 5,\n",
    "    'MODEL': 'efficientnet_b3',\n",
    "    'LOSS': 'FocalLoss',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "        self.feature = []\n",
    "        \n",
    "        for img_path in self.img_path_list:\n",
    "            image = cv2.imread(img_path)\n",
    "            if self.transforms is not None:\n",
    "                image = self.transforms(image=image)['image']\n",
    "            self.feature.append(image)\n",
    "        \n",
    "    def __getitem__(self, index):        \n",
    "        if self.label_list is not None:\n",
    "            return self.feature[index], self.label_list[index]\n",
    "        else:\n",
    "            return self.feature[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE_W'],CFG['IMG_SIZE_W']),\n",
    "                            A.HorizontalFlip(always_apply=False, p=0.5),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE_W'],CFG['IMG_SIZE_W']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_classes=18, pretrained=True):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.pretrained = pretrained\n",
    "        \n",
    "        # self.model = timm.create_model('efficientnet_b0', pretrained=self.pretrained)\n",
    "        self.model = timm.create_model(CFG['MODEL'], pretrained=self.pretrained)\n",
    "        self.fc = nn.Sequential(nn.Dropout(p=0.2, inplace=True),\n",
    "                               nn.Linear(1000, 512),\n",
    "                               nn.Dropout(p=0.2, inplace=True),\n",
    "                               nn.Linear(512, num_classes),\n",
    "                               )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/opt/ml/input/data/eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(test_dir + '/info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [os.path.join(test_dir, 'images', img_id) for img_id in df.ImageID]\n",
    "\n",
    "test_dataset = CustomDataset(image_paths, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(iter(test_loader)):\n",
    "            imgs = imgs.to(device)\n",
    "            \n",
    "            logit = model(imgs)\n",
    "\n",
    "            preds += logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_idx = 5\n",
    "model_weights = torch.load(glob(f'/opt/ml/models/{project_idx}/ALL/*')[0])\n",
    "model = CustomModel()\n",
    "model.load_state_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e990a5b5190448da39499b0850941ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=394.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_preds = inference(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b3_5.csv - test inference is done!\n"
     ]
    }
   ],
   "source": [
    "df['ans'] = model_preds\n",
    "df.to_csv(os.path.join(test_dir, 'submits', f'{CFG[\"MODEL\"]}_{project_idx}.csv'), index=False)\n",
    "print(f'{CFG[\"MODEL\"]}_{project_idx}.csv - test inference is done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Wrong Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15120 3780\n"
     ]
    }
   ],
   "source": [
    "train_dir = '/opt/ml/input/data/train'\n",
    "\n",
    "all_img_path = glob(os.path.join(train_dir, 'images', '*', '*'))\n",
    "\n",
    "train_df = pd.DataFrame(columns=['id', 'path', 'mask_label', 'gender_label', 'age_label', 'label'])\n",
    "train_df['path'] = all_img_path\n",
    "\n",
    "_file_names = {\"mask1\": 0, \"mask2\": 0, \"mask3\": 0, \"mask4\": 0, \"mask5\": 0, \"incorrect_mask\": 1, \"normal\": 2}\n",
    "train_df['id'] = train_df['path'].apply(lambda x : (str(x).split('/')[7]).split('_')[0])\n",
    "train_df['mask_label'] = train_df['path'].apply(lambda x : _file_names[os.path.splitext(x.split('/')[-1])[0]])\n",
    "\n",
    "_gender_labels = {\"male\": 0, \"female\": 1}\n",
    "train_df['id'] = train_df['path'].apply(lambda x : (str(x).split('/')[7]).split('_')[0])\n",
    "train_df['gender_label'] = train_df['path'].apply(lambda x : _gender_labels[(str(x).split('/')[7]).split('_')[1]])\n",
    "\n",
    "train_df['id'] = train_df['path'].apply(lambda x : (str(x).split('/')[7]).split('_')[0])\n",
    "train_df['age_label'] = train_df['path'].apply(lambda x : int((str(x).split('/')[7]).split('_')[3]))\n",
    "\n",
    "train_df['age_label'].loc[train_df['age_label'] < 30] = 0\n",
    "train_df['age_label'].loc[(train_df['age_label'] >= 30) & (train_df['age_label'] < 60)] = 1\n",
    "train_df['age_label'].loc[train_df['age_label'] >= 60] = 2\n",
    "\n",
    "train_df['label'] = train_df.apply(lambda x : (x['mask_label'] * 6 + x['gender_label']*3 + x['age_label']), axis=1)\n",
    "\n",
    "train_, val_, _, _ = train_test_split(train_df, train_df['label'], test_size=0.2, random_state=CFG['SEED'], stratify=train_df['label'])\n",
    "print(len(train_), len(val_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset = CustomDataset(val_['path'].values, val_['label'].values, test_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=8)\n",
    "\n",
    "model_weights = torch.load(glob(f'/opt/ml/models/{project_idx}/ALL/*')[0])\n",
    "model = CustomModel().to(device)\n",
    "model.load_state_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d42836b0d24d7d8486412f259813eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target, prediction = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(iter(val_loader)):\n",
    "        imgs = imgs.float().to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        logit = model(imgs)        \n",
    "        pred = logit.argmax(dim=1)\n",
    "        \n",
    "        indices = (pred != labels).nonzero().squeeze()\n",
    "        if indices.nelement() != 0:\n",
    "            target.append(imgs[indices])\n",
    "            prediction.append((pred[indices], labels[indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3780\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(val_))\n",
    "print(len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
